{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pykospacing import Spacing\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import ace_tools as tools\n",
    "import ace_tools_open as tools\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 읽기\n",
    "with open('data.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# 공백 제거 (모든 공백 문자 삭제)\n",
    "content = \"\".join(content.split())\n",
    "\n",
    "# 문장 분리 (정규 표현식 사용)\n",
    "sentences = re.split(r'[.!?]', content)\n",
    "\n",
    "# 빈 문장 제거 및 큰따옴표 제거\n",
    "clean_sentences = [re.sub(r'\"', '', sentence) for sentence in sentences if sentence]\n",
    "\n",
    "# 파일에 저장\n",
    "with open('no_space_sentence.txt', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(\"\\n\".join(clean_sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 좋음 -> 이걸로 띄여쓰기 복원을 하고 있다.\n",
    "\n",
    "# pykospacing 객체 생성\n",
    "spacing = Spacing()\n",
    "\n",
    "# 입력 파일 읽기\n",
    "with open('no_space_sentence.txt', 'r', encoding='utf-8') as input_file:\n",
    "    sentences = input_file.readlines()\n",
    "\n",
    "# 공백 복원\n",
    "spaced_sentences = [spacing(sentence.strip()) for sentence in sentences]\n",
    "\n",
    "# 결과 저장\n",
    "with open('yes_space_sentence.txt', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(\"\\n\".join(spaced_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Sentence-BERT 모델 로드 (한국어 지원 모델 사용) -> 로그인 하고 귀찮아서 그냥 다른거 쓴다\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "\n",
    "\n",
    "# 2️⃣ 파일에서 문장 읽기\n",
    "with open('yes_space_sentence.txt', 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.strip() for line in file.readlines() if line.strip()]\n",
    "\n",
    "# 3️⃣ 문장 임베딩 변환 (각 문장을 벡터로 변환)\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# 4️⃣ 문장 간 유사도 계산 (코사인 유사도 활용)\n",
    "similarity_matrix = util.pytorch_cos_sim(sentence_embeddings, sentence_embeddings).numpy()\n",
    "\n",
    "# 5️⃣ 데이터프레임 생성 (문장 간 유사도 표시)\n",
    "df_similarity = pd.DataFrame(similarity_matrix, index=sentences, columns=sentences)\n",
    "\n",
    "# 파일로 저장\n",
    "df_similarity.to_excel(\"sentence_similarity.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Sentence-BERT 모델 로드 (한국어 지원 모델 사용) -> 로그인 하고 귀찮아서 그냥 다른거 쓴다\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "\n",
    "\n",
    "# 2️⃣ 파일에서 문장 읽기\n",
    "with open('yes_space_sentence.txt', 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.strip() for line in file.readlines() if line.strip()]\n",
    "\n",
    "# 3️⃣ 문장 임베딩 변환 (각 문장을 벡터로 변환)\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# 4️⃣ 문장 간 유사도 계산 (코사인 유사도 활용)\n",
    "similarity_matrix = util.pytorch_cos_sim(sentence_embeddings, sentence_embeddings).numpy()\n",
    "\n",
    "# 5️⃣ 데이터프레임 생성 (문장 간 유사도 표시)\n",
    "df_similarity = pd.DataFrame(similarity_matrix, index=sentences, columns=sentences)\n",
    "\n",
    "# 파일로 저장\n",
    "with open(\"sentence_similarity.pkl\", \"wb\") as pkl_file:\n",
    "    pickle.dump(df_similarity, pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 표현\n",
    "\n",
    "# 1️⃣ 저장된 pickle 파일 로드\n",
    "with open(\"sentence_similarity.pkl\", \"rb\") as pkl_file:\n",
    "    df_similarity = pickle.load(pkl_file)\n",
    "\n",
    "# 2️⃣ 히트맵 시각화\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df_similarity, annot=False, cmap=\"coolwarm\", xticklabels=False, yticklabels=False)\n",
    "\n",
    "# 3️⃣ 그래프 타이틀 추가\n",
    "plt.title(\"Sentence Similarity Heatmap\", fontsize=14)\n",
    "plt.xlabel(\"Sentences\", fontsize=12)\n",
    "plt.ylabel(\"Sentences\", fontsize=12)\n",
    "\n",
    "# 4️⃣ 시각화 출력\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ 저장된 pickle 파일 로드\n",
    "with open(\"sentence_similarity.pkl\", \"rb\") as pkl_file:\n",
    "    df_similarity = pickle.load(pkl_file)\n",
    "\n",
    "# 2️⃣ 유사도 기준 설정 (0.8 ≤ 유사도 < 0.9)\n",
    "threshold_low = 0.8\n",
    "threshold_high = 0.9  # 0.9 이상은 제외\n",
    "\n",
    "# 3️⃣ 유사도가 지정된 범위에 속하는 문장 쌍 추출 (자기 자신 제외)\n",
    "similar_sentences = []\n",
    "for i in range(len(df_similarity)):\n",
    "    for j in range(i + 1, len(df_similarity)):  # 대각선 기준 중복 제거\n",
    "        similarity_score = round(df_similarity.iloc[i, j], 6)  # 소수점 6자리까지 반올림\n",
    "        if threshold_low <= similarity_score < threshold_high:  # 0.8 이상, 0.9 미만\n",
    "            sentence1 = df_similarity.index[i]\n",
    "            sentence2 = df_similarity.columns[j]\n",
    "            similar_sentences.append((sentence1, sentence2, similarity_score))\n",
    "\n",
    "# 4️⃣ 결과를 DataFrame으로 변환\n",
    "df_high_similarity = pd.DataFrame(similar_sentences, columns=[\"문장1\", \"문장2\", \"유사도\"])\n",
    "\n",
    "# 5️⃣ 유사도 높은 순으로 정렬\n",
    "df_high_similarity = df_high_similarity.sort_values(by=\"유사도\", ascending=False)\n",
    "\n",
    "# 6️⃣ 결과 출력 (상위 10개)\n",
    "print(df_high_similarity.head(10))  # 더 보고 싶으면 숫자 조정 가능\n",
    "\n",
    "# 7️⃣ 파일로 저장 (옵션)\n",
    "df_high_similarity.to_excel(\"high_similarity_08_09.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 하하하하하ㅏ하 \" 이거를 지워야하는구나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
